{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "## emoticons\n",
    "emoticons_str = r\"\"\"\n",
    "  (?:\n",
    "    [:=;] # Eyes\n",
    "    [oO\\-]? # Nose (optional)\n",
    "    [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "  )\"\"\"\n",
    " \n",
    "## words\n",
    "regex_str = [\n",
    "  emoticons_str,\n",
    "  r'<[^>]+>', # HTML tags\n",
    "  r'(?:@[\\w_]+)', # @-mentions\n",
    "  r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "  r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "\n",
    "  r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "  r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "  r'(?:[\\w_]+)', # other words\n",
    "  r'(?:\\S)' # anything else\n",
    "]\n",
    "\n",
    "## compile regex\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "def tokenize(string):\n",
    "\treturn tokens_re.findall(string)\n",
    "\n",
    "def removable(token):\n",
    "\tisEmoticon = True if emoticon_re.search(token) else False\n",
    "\tisRemovable = token in [',', '.', ':', ';']\n",
    "\treturn (isEmoticon or isRemovable)\n",
    "\n",
    "# pre_processor\n",
    "def pre_process(string, lowercase=False):\n",
    "\ttokens = tokenize(string)\n",
    "\ttokens = [ token for token in tokens if not removable(token)]\n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load curated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_curated_tweets(csv_file, encoding='latin-1'):\n",
    "    df_curated = pd.read_csv(csv_file, encoding=encoding)\n",
    "    df_curated = df_curated[['id', 'tweet', 'class']]\n",
    "    return df_curated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Load unlabeled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_unlabeled_tweets(csv_file, encoding='latin-1'):\n",
    "    df_curated = pd.read_csv(csv_file, encoding=encoding)\n",
    "    df_curated = df_curated[['id', 'tweet']]\n",
    "    return df_curated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Write tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_tweets(csv_file, df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def build_classifier(df_curated, df_all):\n",
    "    vec = CountVectorizer(tokenizer=pre_process)\n",
    "    vec.fit(df_all.tweet)\n",
    "    bagofwords = vec.transform(df_curated.tweet)\n",
    "    bagofwords = bagofwords.toarray()\n",
    "    clf = MultinomialNB().fit(bagofwords, df_curated['class'])\n",
    "    return vec, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Update classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_classifier(vec, clf, new_curated):\n",
    "    bagofwords = vec.fit_transform(df_new_curated.tweet)\n",
    "    bagofwords = bagofwords.toarray()\n",
    "    clf = clf.partial_fit(bagofwords, df_new_curated['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test partial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_curated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-533a40071d59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_curated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_curated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_curated\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbagofwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_curated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_curated' is not defined"
     ]
    }
   ],
   "source": [
    "df_curated.reindex(np.random.permutation(df_curated.index))\n",
    "train_size = int(len(df_curated) * .75)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(tokenizer=pre_process)\n",
    "bagofwords = vec.fit(df_curated.tweet)\n",
    "bagofwords = bagofwords.toarray()\n",
    "train = bagofwords[:train_size,:]\n",
    "test = bagofwords[train_size:,:]\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(train, df_curated[:train_size]['class'])\n",
    "clf = clf.partial_fit(test, df_curated[train_size:]['class'])\n",
    "predicted = clf.predict(test)\n",
    "pd.crosstab(df_curated[train_size:]['class'], predicted,\n",
    "                      rownames=['actual'], colnames=['predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pick uncertain samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_uncertain_samples(sample_size, batch_size, vec, clf, df_unlabeled):\n",
    "    # take random sample of unlabeled\n",
    "    rows = np.random.choice(df_unlabeled.index.values, sample_size)\n",
    "    df_sample = df_unlabeled.ix[rows]\n",
    "    sample = vec.transform(df_sample.tweet)\n",
    "    \n",
    "    # predict them\n",
    "    predicted = clf.predict_log_proba(sample)\n",
    "    predicted = [sum(n) for n in predicted]\n",
    "    \n",
    "    df_sample['predicted'] = predicted\n",
    "    i = np.argpartition(np.array([-n for n in predicted]), batch_size)[:batch_size]\n",
    "    df_sample = df_sample.iloc[i]\n",
    "    \n",
    "    # pick batch_size with least uncertainty\n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curated_csv = '../twitfem/curated/davidt1.csv'\n",
    "unlabeled_csv = '../twitfem/twitfem.csv'\n",
    "df_curated = load_curated_tweets(curated_csv)\n",
    "df_unlabeled = load_unlabeled_tweets(unlabeled_csv)\n",
    "vec, clf = build_classifier(df_curated, df_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/CentOS-6/tools/python-3.3.2/lib/python3.3/site-packages/IPython/kernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>837928</th>\n",
       "      <td> 585887523710205952</td>\n",
       "      <td> #FIFA ,When will you judge them http://t.co/8m...</td>\n",
       "      <td>-3.299647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                              tweet  \\\n",
       "837928  585887523710205952  #FIFA ,When will you judge them http://t.co/8m...   \n",
       "\n",
       "        predicted  \n",
       "837928  -3.299647  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample= pick_uncertain_samples(1000, 1, vec, clf, df_unlabeled)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-34-b8c4634ff38c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-34-b8c4634ff38c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def main(argv):\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def main(argv):\n",
    "    try:\n",
    "        curated_csv = argv[1]\n",
    "        batch_size = argv[2]\n",
    "    except IndexError:\n",
    "        print('Missing command line argument.')\n",
    "        \n",
    "    build_classifier(curated_csv)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
